{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHQBnSHH4pHh/tzdtucwN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJalali-KIT/BlackHole/blob/main/BlackHole_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2UlbUrED5Eg",
        "outputId": "03d9e265-19b8-4211-e510-f99d8bbebb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# Change working path\n",
        "os.chdir('/content/drive/MyDrive/Research/MOF/Black_Hole')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mqkBwMjECRf",
        "outputId": "ccb534f3-4a23-4265-87ea-548d1b2607b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef, roc_auc_score\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tensorflow.keras.models import load_model\n",
        "import warnings\n",
        "from rdkit import RDLogger\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Suppress specific deprecation warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Additionally, suppress RDKit warnings globally\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "def generate_fingerprint(smiles):\n",
        "    \"\"\"Generates a molecular fingerprint given a SMILES string.\"\"\"\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return np.zeros((1024,), dtype=float)  # Return an array of zeros if molecule can't be parsed\n",
        "        return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024), dtype=float)\n",
        "    except Exception as e:\n",
        "        print(f\"SMILES Parse Error: {e}\")\n",
        "        return np.zeros((1024,), dtype=float)  # Return an array of zeros in case of an error\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Calculate percentage accuracy for each element in the confusion matrix\n",
        "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "    # Combine counts and percentages for display\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_percentage[i, j]\n",
        "            annot[i, j] = f'{c}\\n({p:.1f}%)'  # Count and percentage\n",
        "\n",
        "    # Plot the confusion matrix with annotations\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', xticklabels=classes, yticklabels=classes, cbar=False)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()\n",
        "\n",
        "def label_encode_metal_names(metal_names):\n",
        "    \"\"\"Encodes metal names as integers.\"\"\"\n",
        "    metal_dict = {metal: idx for idx, metal in enumerate(np.unique(metal_names))}\n",
        "    return np.array([metal_dict[metal] for metal in metal_names])\n",
        "\n",
        "def preprocess_graph(graph, features):\n",
        "    # Determine the dimensionality of the feature vectors\n",
        "    feature_dimension = features.shape[1]\n",
        "\n",
        "    # Convert the graph to an adjacency matrix\n",
        "    adjacency_matrix = nx.adjacency_matrix(graph).toarray()\n",
        "\n",
        "    # Initialize an empty list to store feature vectors\n",
        "    feature_vectors = []\n",
        "\n",
        "    # Create a mapping from node labels to integer indices\n",
        "    node_to_index = {node: index for index, node in enumerate(graph.nodes())}\n",
        "\n",
        "    # Iterate over nodes in the graph\n",
        "    for node in graph.nodes():\n",
        "        # Get the integer index corresponding to the node label\n",
        "        node_index = node_to_index[node]\n",
        "        # Check if the node index is valid\n",
        "        if node_index < len(features):\n",
        "            # Append the feature vector corresponding to the node index\n",
        "            feature_vectors.append(features[node_index])\n",
        "        else:\n",
        "            # If the node index is out of range, assign a default feature vector\n",
        "            feature_vectors.append(np.zeros((feature_dimension,)))\n",
        "\n",
        "    # Convert the list of feature vectors to a numpy array\n",
        "    feature_matrix = np.array(feature_vectors)\n",
        "\n",
        "    return adjacency_matrix, feature_matrix\n",
        "\n",
        "def build_gcn_model(input_shape_feature, input_shape_adjacency, num_classes):\n",
        "    # Define input layers\n",
        "    x_inp_feature = Input(shape=(input_shape_feature,))\n",
        "    x_inp_adjacency = Input(shape=(input_shape_adjacency,))\n",
        "\n",
        "    # Feature processing with multiple layers\n",
        "    x_feature = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x_inp_feature)\n",
        "    x_feature = Dropout(0.5)(x_feature)\n",
        "    x_feature = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_feature)\n",
        "    x_feature = Dropout(0.3)(x_feature)\n",
        "\n",
        "    # Adjacency processing with multiple layers\n",
        "    x_adjacency = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x_inp_adjacency)\n",
        "    x_adjacency = Dropout(0.5)(x_adjacency)\n",
        "    x_adjacency = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_adjacency)\n",
        "    x_adjacency = Dropout(0.3)(x_adjacency)\n",
        "\n",
        "    # Concatenate feature and adjacency outputs\n",
        "    x = concatenate([x_feature, x_adjacency])\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=[x_inp_feature, x_inp_adjacency], outputs=output)\n",
        "\n",
        "    # Using a smaller learning rate\n",
        "    optimizer = Adam(learning_rate=0.0009)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_feedforward_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_shape,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def train_gcn_model(model, adjacency_matrix, feature_matrix, labels, epochs, batch_size):\n",
        "    if model is not None and adjacency_matrix is not None and feature_matrix is not None and labels is not None:\n",
        "        # Early stopping to prevent overfitting\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        # ModelCheckpoint to save the best model\n",
        "        model_checkpoint = ModelCheckpoint('best_gcn_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "        start_time = time.time()\n",
        "        # Train the model\n",
        "        history = model.fit([feature_matrix, adjacency_matrix], labels,\n",
        "                            epochs=epochs, batch_size=batch_size,\n",
        "                            validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate total training time\n",
        "        total_training_time = end_time - start_time\n",
        "        print(f\"Total training time: {total_training_time:.2f} seconds\")\n",
        "\n",
        "        return history\n",
        "    else:\n",
        "        print(\"Error: One or more input arguments to train_gcn_model is None.\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    edge_list_filenames = [\n",
        "        'sparsified_graph_edges_blackhole_0.1.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.2.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.3.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.4.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.5.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.6.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.7.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.8.csv',\n",
        "        'sparsified_graph_edges_blackhole_0.9.csv'\n",
        "    ]\n",
        "\n",
        "    summary_data_filename = '1M1L3D_summary.csv'\n",
        "\n",
        "    # Initialize lists to track accuracies and thresholds\n",
        "    accuracies = []\n",
        "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "    # Loop through all edge list files\n",
        "    for edges_list_filename, threshold in zip(edge_list_filenames, thresholds):\n",
        "        print(f\"Processing edge list file: {edges_list_filename}\")\n",
        "\n",
        "        # Load data\n",
        "        edges_list = pd.read_csv(edges_list_filename, header=None, names=['source', 'target', 'weight'], delimiter=' ')\n",
        "        summary_data = pd.read_csv(summary_data_filename)\n",
        "\n",
        "        node_labels_source = edges_list['source'].astype(str).unique()\n",
        "        node_labels_target = edges_list['target'].astype(str).unique()\n",
        "        node_labels = np.unique(np.concatenate((node_labels_source, node_labels_target)))\n",
        "        node_labels = list(set(node_labels))\n",
        "\n",
        "        print(\"Unique node labels:\", len(node_labels))\n",
        "\n",
        "        summary_data_filtered = summary_data[summary_data['refcode'].isin(node_labels)]\n",
        "        print(\"Filtered summary data:\\n\", len(summary_data_filtered))\n",
        "\n",
        "        if not summary_data_filtered.empty:\n",
        "            linker_smiles = summary_data_filtered['linker SMILES']\n",
        "            if not linker_smiles.empty:\n",
        "                # Generate features\n",
        "                linker_features = np.stack(linker_smiles.dropna().apply(generate_fingerprint).values)\n",
        "                metal_names = summary_data_filtered['metal']\n",
        "                metal_features = label_encode_metal_names(metal_names).reshape(-1, 1)\n",
        "\n",
        "                other_features = summary_data_filtered[['Largest Cavity Diameter', 'Largest Free Sphere']].values.astype('float32')\n",
        "                features = np.concatenate((linker_features, metal_features, other_features), axis=1)\n",
        "\n",
        "                # Generate labels\n",
        "                summary_data_filtered['PLD_category'] = pd.cut(\n",
        "                    summary_data_filtered['Pore Limiting Diameter'],\n",
        "                    bins=[-np.inf, 2.4, 4.4, 5.9, np.inf],\n",
        "                    labels=['nonporous', 'small pore', 'medium pore', 'large pore']\n",
        "                )\n",
        "                labels = pd.get_dummies(summary_data_filtered['PLD_category']).values\n",
        "\n",
        "                # Split the data into training and testing sets\n",
        "                X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=56)\n",
        "\n",
        "                # Load the sparsified graph\n",
        "                graph = nx.read_weighted_edgelist(edges_list_filename)\n",
        "\n",
        "                # Preprocess the graph data\n",
        "                adjacency_matrix, feature_matrix = preprocess_graph(graph, features)\n",
        "\n",
        "                # Split the adjacency and feature matrices accordingly\n",
        "                adj_train, adj_test, feat_train, feat_test = train_test_split(adjacency_matrix, feature_matrix, test_size=0.2, random_state=56)\n",
        "\n",
        "                # Provide the number of classes\n",
        "                num_classes = labels.shape[1]\n",
        "\n",
        "                # Build the GCN model\n",
        "                gcn_model = build_gcn_model(feat_train.shape[1], adj_train.shape[1], num_classes)\n",
        "\n",
        "                # Train the GCN model\n",
        "                history = train_gcn_model(gcn_model, adj_train, feat_train, y_train, epochs=40, batch_size=32)\n",
        "\n",
        "                # Evaluate the model on the test set\n",
        "                test_loss, test_accuracy = gcn_model.evaluate([feat_test, adj_test], y_test, verbose=0)\n",
        "                print(f'Test Accuracy for threshold {threshold}: {test_accuracy}')\n",
        "\n",
        "                # Track the accuracy\n",
        "                accuracies.append(test_accuracy)\n",
        "\n",
        "                # Continue with your evaluation metrics and comparison logic\n",
        "                # ...\n",
        "            else:\n",
        "                print(\"Error: linker_smiles column is empty.\")\n",
        "        else:\n",
        "            print(\"Error: summary_data_filtered DataFrame is empty.\")\n",
        "\n",
        "    # Plot the accuracy comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(thresholds, accuracies, marker='o', color='b', label='Test Accuracy')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('GCN Test Accuracy Across Different Sparsification Thresholds')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "FpoIPjwQEOJ1",
        "outputId": "dd04dff5-19d0-40c8-86fd-cb1c9350238c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing edge list file: sparsified_graph_edges_blackhole_0.1.csv\n",
            "Unique node labels: 8810\n",
            "Filtered summary data:\n",
            " 8810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5192077cab59>:233: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  summary_data_filtered['PLD_category'] = pd.cut(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4562 - loss: 4.0593\n",
            "Epoch 1: val_loss improved from inf to 1.38494, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.4571 - loss: 4.0437 - val_accuracy: 0.6376 - val_loss: 1.3849\n",
            "Epoch 2/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6494 - loss: 1.3133\n",
            "Epoch 2: val_loss improved from 1.38494 to 1.01015, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.6495 - loss: 1.3128 - val_accuracy: 0.6631 - val_loss: 1.0101\n",
            "Epoch 3/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6805 - loss: 1.0059\n",
            "Epoch 3: val_loss improved from 1.01015 to 0.86158, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6806 - loss: 1.0057 - val_accuracy: 0.6915 - val_loss: 0.8616\n",
            "Epoch 4/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7046 - loss: 0.8871\n",
            "Epoch 4: val_loss improved from 0.86158 to 0.77832, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7046 - loss: 0.8868 - val_accuracy: 0.7128 - val_loss: 0.7783\n",
            "Epoch 5/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7116 - loss: 0.8190\n",
            "Epoch 5: val_loss improved from 0.77832 to 0.75536, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7116 - loss: 0.8190 - val_accuracy: 0.7234 - val_loss: 0.7554\n",
            "Epoch 6/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7059 - loss: 0.7981\n",
            "Epoch 6: val_loss improved from 0.75536 to 0.71839, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.7060 - loss: 0.7980 - val_accuracy: 0.7340 - val_loss: 0.7184\n",
            "Epoch 7/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7172 - loss: 0.7597\n",
            "Epoch 7: val_loss did not improve from 0.71839\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.7171 - loss: 0.7597 - val_accuracy: 0.7149 - val_loss: 0.7214\n",
            "Epoch 8/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7234 - loss: 0.7501\n",
            "Epoch 8: val_loss improved from 0.71839 to 0.69923, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7234 - loss: 0.7502 - val_accuracy: 0.7262 - val_loss: 0.6992\n",
            "Epoch 9/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7113 - loss: 0.7504\n",
            "Epoch 9: val_loss did not improve from 0.69923\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7114 - loss: 0.7504 - val_accuracy: 0.7177 - val_loss: 0.7172\n",
            "Epoch 10/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7192 - loss: 0.7411\n",
            "Epoch 10: val_loss improved from 0.69923 to 0.68052, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7192 - loss: 0.7410 - val_accuracy: 0.7411 - val_loss: 0.6805\n",
            "Epoch 11/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7227 - loss: 0.7273\n",
            "Epoch 11: val_loss did not improve from 0.68052\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7227 - loss: 0.7273 - val_accuracy: 0.7489 - val_loss: 0.6872\n",
            "Epoch 12/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7205 - loss: 0.7399\n",
            "Epoch 12: val_loss improved from 0.68052 to 0.67339, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7205 - loss: 0.7398 - val_accuracy: 0.7397 - val_loss: 0.6734\n",
            "Epoch 13/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7376 - loss: 0.6983\n",
            "Epoch 13: val_loss did not improve from 0.67339\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.7376 - loss: 0.6983 - val_accuracy: 0.7333 - val_loss: 0.6772\n",
            "Epoch 14/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7292 - loss: 0.7062\n",
            "Epoch 14: val_loss improved from 0.67339 to 0.66412, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7291 - loss: 0.7064 - val_accuracy: 0.7603 - val_loss: 0.6641\n",
            "Epoch 15/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.6974\n",
            "Epoch 15: val_loss did not improve from 0.66412\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7344 - loss: 0.6975 - val_accuracy: 0.7248 - val_loss: 0.6887\n",
            "Epoch 16/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7321 - loss: 0.7143\n",
            "Epoch 16: val_loss improved from 0.66412 to 0.66348, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7321 - loss: 0.7141 - val_accuracy: 0.7468 - val_loss: 0.6635\n",
            "Epoch 17/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7222 - loss: 0.7064\n",
            "Epoch 17: val_loss did not improve from 0.66348\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7223 - loss: 0.7064 - val_accuracy: 0.7404 - val_loss: 0.6766\n",
            "Epoch 18/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7335 - loss: 0.7000\n",
            "Epoch 18: val_loss did not improve from 0.66348\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.7335 - loss: 0.7001 - val_accuracy: 0.7433 - val_loss: 0.6828\n",
            "Epoch 19/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7365 - loss: 0.6996\n",
            "Epoch 19: val_loss did not improve from 0.66348\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7365 - loss: 0.6995 - val_accuracy: 0.7191 - val_loss: 0.6732\n",
            "Epoch 20/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7330 - loss: 0.7068\n",
            "Epoch 20: val_loss improved from 0.66348 to 0.66326, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.7330 - loss: 0.7067 - val_accuracy: 0.7631 - val_loss: 0.6633\n",
            "Epoch 21/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7478 - loss: 0.6922\n",
            "Epoch 21: val_loss improved from 0.66326 to 0.64802, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7476 - loss: 0.6922 - val_accuracy: 0.7553 - val_loss: 0.6480\n",
            "Epoch 22/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7462 - loss: 0.6881\n",
            "Epoch 22: val_loss did not improve from 0.64802\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7461 - loss: 0.6882 - val_accuracy: 0.7574 - val_loss: 0.6674\n",
            "Epoch 23/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7530 - loss: 0.6723\n",
            "Epoch 23: val_loss improved from 0.64802 to 0.64672, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7529 - loss: 0.6724 - val_accuracy: 0.7546 - val_loss: 0.6467\n",
            "Epoch 24/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7382 - loss: 0.6785\n",
            "Epoch 24: val_loss did not improve from 0.64672\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.7382 - loss: 0.6785 - val_accuracy: 0.7560 - val_loss: 0.6537\n",
            "Epoch 25/40\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7354 - loss: 0.6786\n",
            "Epoch 25: val_loss did not improve from 0.64672\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.7354 - loss: 0.6787 - val_accuracy: 0.7582 - val_loss: 0.6514\n",
            "Epoch 26/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7528 - loss: 0.6678\n",
            "Epoch 26: val_loss did not improve from 0.64672\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7528 - loss: 0.6679 - val_accuracy: 0.7567 - val_loss: 0.6584\n",
            "Epoch 27/40\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7473 - loss: 0.6678\n",
            "Epoch 27: val_loss did not improve from 0.64672\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7471 - loss: 0.6681 - val_accuracy: 0.7553 - val_loss: 0.6571\n",
            "Epoch 28/40\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7487 - loss: 0.6920\n",
            "Epoch 28: val_loss did not improve from 0.64672\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7487 - loss: 0.6918 - val_accuracy: 0.7617 - val_loss: 0.6512\n",
            "Total training time: 173.57 seconds\n",
            "Test Accuracy for threshold 0.1: 0.7553915977478027\n",
            "Processing edge list file: sparsified_graph_edges_blackhole_0.2.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'sparsified_graph_edges_blackhole_0.2.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5192077cab59>\u001b[0m in \u001b[0;36m<cell line: 184>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0medges_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_list_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0msummary_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_data_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sparsified_graph_edges_blackhole_0.2.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on Cintinius PLD**"
      ],
      "metadata": {
        "id": "f4SC0AHNcXOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from rdkit import RDLogger\n",
        "\n",
        "# Suppress specific deprecation warnings and RDKit warnings globally\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "def generate_fingerprint(smiles):\n",
        "    \"\"\"Generates a molecular fingerprint given a SMILES string.\"\"\"\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return np.zeros((1024,), dtype=float)  # Return an array of zeros if molecule can't be parsed\n",
        "        return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024), dtype=float)\n",
        "    except Exception as e:\n",
        "        print(f\"SMILES Parse Error: {e}\")\n",
        "        return np.zeros((1024,), dtype=float)  # Return an array of zeros in case of an error\n",
        "\n",
        "def preprocess_graph(graph, features):\n",
        "    \"\"\"Preprocesses graph data into adjacency and feature matrices.\"\"\"\n",
        "    feature_dimension = features.shape[1]\n",
        "    adjacency_matrix = nx.adjacency_matrix(graph).toarray()\n",
        "    feature_vectors = []\n",
        "\n",
        "    node_to_index = {node: index for index, node in enumerate(graph.nodes())}\n",
        "    for node in graph.nodes():\n",
        "        node_index = node_to_index[node]\n",
        "        if node_index < len(features):\n",
        "            feature_vectors.append(features[node_index])\n",
        "        else:\n",
        "            feature_vectors.append(np.zeros((feature_dimension,)))\n",
        "\n",
        "    feature_matrix = np.array(feature_vectors)\n",
        "    return adjacency_matrix, feature_matrix\n",
        "\n",
        "def build_gcn_model(input_shape_feature, input_shape_adjacency):\n",
        "    \"\"\"Builds a Graph Convolutional Network model for regression.\"\"\"\n",
        "    x_inp_feature = Input(shape=(input_shape_feature,))\n",
        "    x_inp_adjacency = Input(shape=(input_shape_adjacency,))\n",
        "\n",
        "    x_feature = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x_inp_feature)\n",
        "    x_feature = Dropout(0.5)(x_feature)\n",
        "    x_feature = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_feature)\n",
        "    x_feature = Dropout(0.5)(x_feature)\n",
        "\n",
        "    x_adjacency = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x_inp_adjacency)\n",
        "    x_adjacency = Dropout(0.5)(x_adjacency)\n",
        "    x_adjacency = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_adjacency)\n",
        "    x_adjacency = Dropout(0.5)(x_adjacency)\n",
        "\n",
        "    x = concatenate([x_feature, x_adjacency])\n",
        "    output = Dense(1)(x)  # Single output node for regression\n",
        "\n",
        "    model = Model(inputs=[x_inp_feature, x_inp_adjacency], outputs=output)\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "    return model\n",
        "\n",
        "def train_gcn_model(model, adjacency_matrix, feature_matrix, labels, epochs, batch_size):\n",
        "    \"\"\"Trains the GCN model and returns the training history.\"\"\"\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint('best_gcn_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "    history = model.fit([feature_matrix, adjacency_matrix], labels,\n",
        "                        epochs=epochs, batch_size=batch_size,\n",
        "                        validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "    return history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "    edge_list_filename = 'sparsified_graph_edges_blackhole_0.1.csv'\n",
        "    summary_data_filename = '1M1L3D_summary.csv'\n",
        "\n",
        "\n",
        "    edges_list = pd.read_csv(edge_list_filename, header=None, names=['source', 'target', 'weight'], delimiter=' ')\n",
        "    summary_data = pd.read_csv(summary_data_filename)\n",
        "\n",
        "    node_labels_source = edges_list['source'].astype(str).unique()\n",
        "    node_labels_target = edges_list['target'].astype(str).unique()\n",
        "    node_labels = np.unique(np.concatenate((node_labels_source, node_labels_target)))\n",
        "\n",
        "    summary_data_filtered = summary_data[summary_data['refcode'].isin(node_labels)]\n",
        "\n",
        "    linker_smiles = summary_data_filtered['linker SMILES']\n",
        "    linker_features = np.stack(linker_smiles.dropna().apply(generate_fingerprint).values)\n",
        "\n",
        "    features = linker_features\n",
        "    labels = summary_data_filtered['Pore Limiting Diameter'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    graph = nx.read_weighted_edgelist(edge_list_filename)\n",
        "    adjacency_matrix, feature_matrix = preprocess_graph(graph, features)\n",
        "\n",
        "    adj_train, adj_test, feat_train, feat_test = train_test_split(adjacency_matrix, feature_matrix, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = build_gcn_model(feat_train.shape[1], adj_train.shape[1])\n",
        "    history = train_gcn_model(model, adj_train, feat_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "    test_loss, test_rmse = model.evaluate([feat_test, adj_test], y_test, verbose=0)\n",
        "    print(f'Test RMSE: {test_rmse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G-_UnLsXccoj",
        "outputId": "9f422f67-87a1-4365-d4df-d92ef8b279cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 23.7612 - root_mean_squared_error: 4.2479\n",
            "Epoch 1: val_loss improved from inf to 13.58128, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 23.7418 - root_mean_squared_error: 4.2460 - val_loss: 13.5813 - val_root_mean_squared_error: 3.0445\n",
            "Epoch 2/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 13.3102 - root_mean_squared_error: 3.0263\n",
            "Epoch 2: val_loss improved from 13.58128 to 10.56723, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 13.3053 - root_mean_squared_error: 3.0258 - val_loss: 10.5672 - val_root_mean_squared_error: 2.6190\n",
            "Epoch 3/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.6582 - root_mean_squared_error: 2.8310\n",
            "Epoch 3: val_loss improved from 10.56723 to 9.78767, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 11.6522 - root_mean_squared_error: 2.8302 - val_loss: 9.7877 - val_root_mean_squared_error: 2.5411\n",
            "Epoch 4/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10.0157 - root_mean_squared_error: 2.5963\n",
            "Epoch 4: val_loss improved from 9.78767 to 9.26678, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 10.0201 - root_mean_squared_error: 2.5973 - val_loss: 9.2668 - val_root_mean_squared_error: 2.4941\n",
            "Epoch 5/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.8534 - root_mean_squared_error: 2.6189\n",
            "Epoch 5: val_loss improved from 9.26678 to 8.81541, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 9.8526 - root_mean_squared_error: 2.6189 - val_loss: 8.8154 - val_root_mean_squared_error: 2.4491\n",
            "Epoch 6/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.2669 - root_mean_squared_error: 2.7308\n",
            "Epoch 6: val_loss improved from 8.81541 to 8.47516, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 10.2568 - root_mean_squared_error: 2.7290 - val_loss: 8.4752 - val_root_mean_squared_error: 2.4176\n",
            "Epoch 7/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.7447 - root_mean_squared_error: 2.4789\n",
            "Epoch 7: val_loss improved from 8.47516 to 8.16384, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.7480 - root_mean_squared_error: 2.4798 - val_loss: 8.1638 - val_root_mean_squared_error: 2.3861\n",
            "Epoch 8/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.4683 - root_mean_squared_error: 2.4521\n",
            "Epoch 8: val_loss improved from 8.16384 to 7.90974, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.4693 - root_mean_squared_error: 2.4525 - val_loss: 7.9097 - val_root_mean_squared_error: 2.3619\n",
            "Epoch 9/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.0751 - root_mean_squared_error: 2.4000\n",
            "Epoch 9: val_loss improved from 7.90974 to 7.73514, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 8.0768 - root_mean_squared_error: 2.4004 - val_loss: 7.7351 - val_root_mean_squared_error: 2.3499\n",
            "Epoch 10/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.3918 - root_mean_squared_error: 2.4884\n",
            "Epoch 10: val_loss improved from 7.73514 to 7.60285, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 8.3891 - root_mean_squared_error: 2.4879 - val_loss: 7.6028 - val_root_mean_squared_error: 2.3432\n",
            "Epoch 11/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.4962 - root_mean_squared_error: 2.3243\n",
            "Epoch 11: val_loss improved from 7.60285 to 7.41386, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 7.4993 - root_mean_squared_error: 2.3250 - val_loss: 7.4139 - val_root_mean_squared_error: 2.3221\n",
            "Epoch 12/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.5384 - root_mean_squared_error: 2.3486\n",
            "Epoch 12: val_loss improved from 7.41386 to 7.28576, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.5385 - root_mean_squared_error: 2.3487 - val_loss: 7.2858 - val_root_mean_squared_error: 2.3111\n",
            "Epoch 13/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.4281 - root_mean_squared_error: 2.3444\n",
            "Epoch 13: val_loss improved from 7.28576 to 7.17121, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 7.4284 - root_mean_squared_error: 2.3445 - val_loss: 7.1712 - val_root_mean_squared_error: 2.3012\n",
            "Epoch 14/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.1933 - root_mean_squared_error: 2.3082\n",
            "Epoch 14: val_loss improved from 7.17121 to 7.08547, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 7.1933 - root_mean_squared_error: 2.3082 - val_loss: 7.0855 - val_root_mean_squared_error: 2.2965\n",
            "Epoch 15/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.8001 - root_mean_squared_error: 2.2339\n",
            "Epoch 15: val_loss improved from 7.08547 to 6.98461, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 6.8013 - root_mean_squared_error: 2.2343 - val_loss: 6.9846 - val_root_mean_squared_error: 2.2866\n",
            "Epoch 16/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2463 - root_mean_squared_error: 2.3435\n",
            "Epoch 16: val_loss improved from 6.98461 to 6.96437, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 7.2441 - root_mean_squared_error: 2.3431 - val_loss: 6.9644 - val_root_mean_squared_error: 2.2929\n",
            "Epoch 17/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.6672 - root_mean_squared_error: 2.2286\n",
            "Epoch 17: val_loss improved from 6.96437 to 6.87875, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 6.6676 - root_mean_squared_error: 2.2287 - val_loss: 6.8788 - val_root_mean_squared_error: 2.2838\n",
            "Epoch 18/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.6968 - root_mean_squared_error: 2.2425\n",
            "Epoch 18: val_loss improved from 6.87875 to 6.79380, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.6943 - root_mean_squared_error: 2.2421 - val_loss: 6.7938 - val_root_mean_squared_error: 2.2740\n",
            "Epoch 19/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.9431 - root_mean_squared_error: 2.3048\n",
            "Epoch 19: val_loss did not improve from 6.79380\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 6.9370 - root_mean_squared_error: 2.3035 - val_loss: 6.8074 - val_root_mean_squared_error: 2.2849\n",
            "Epoch 20/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.3386 - root_mean_squared_error: 2.1791\n",
            "Epoch 20: val_loss improved from 6.79380 to 6.66576, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.3389 - root_mean_squared_error: 2.1792 - val_loss: 6.6658 - val_root_mean_squared_error: 2.2614\n",
            "Epoch 21/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.2880 - root_mean_squared_error: 2.1774\n",
            "Epoch 21: val_loss improved from 6.66576 to 6.64402, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 6.2879 - root_mean_squared_error: 2.1774 - val_loss: 6.6440 - val_root_mean_squared_error: 2.2637\n",
            "Epoch 22/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.9294 - root_mean_squared_error: 2.0975\n",
            "Epoch 22: val_loss improved from 6.64402 to 6.60707, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.9312 - root_mean_squared_error: 2.0979 - val_loss: 6.6071 - val_root_mean_squared_error: 2.2616\n",
            "Epoch 23/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.4221 - root_mean_squared_error: 2.2154\n",
            "Epoch 23: val_loss did not improve from 6.60707\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 6.4199 - root_mean_squared_error: 2.2150 - val_loss: 6.6554 - val_root_mean_squared_error: 2.2779\n",
            "Epoch 24/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.6737 - root_mean_squared_error: 2.0498\n",
            "Epoch 24: val_loss improved from 6.60707 to 6.50074, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 5.6772 - root_mean_squared_error: 2.0507 - val_loss: 6.5007 - val_root_mean_squared_error: 2.2492\n",
            "Epoch 25/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.2896 - root_mean_squared_error: 2.2000\n",
            "Epoch 25: val_loss did not improve from 6.50074\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 6.2855 - root_mean_squared_error: 2.1991 - val_loss: 6.5036 - val_root_mean_squared_error: 2.2548\n",
            "Epoch 26/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.9866 - root_mean_squared_error: 2.1368\n",
            "Epoch 26: val_loss improved from 6.50074 to 6.47862, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 5.9858 - root_mean_squared_error: 2.1366 - val_loss: 6.4786 - val_root_mean_squared_error: 2.2543\n",
            "Epoch 27/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.1561 - root_mean_squared_error: 2.1758\n",
            "Epoch 27: val_loss improved from 6.47862 to 6.47654, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.1539 - root_mean_squared_error: 2.1754 - val_loss: 6.4765 - val_root_mean_squared_error: 2.2576\n",
            "Epoch 28/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.8900 - root_mean_squared_error: 2.1222\n",
            "Epoch 28: val_loss improved from 6.47654 to 6.43176, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 5.8891 - root_mean_squared_error: 2.1220 - val_loss: 6.4318 - val_root_mean_squared_error: 2.2520\n",
            "Epoch 29/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.1197 - root_mean_squared_error: 1.9375\n",
            "Epoch 29: val_loss improved from 6.43176 to 6.42612, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 5.1227 - root_mean_squared_error: 1.9382 - val_loss: 6.4261 - val_root_mean_squared_error: 2.2540\n",
            "Epoch 30/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.9473 - root_mean_squared_error: 2.1377\n",
            "Epoch 30: val_loss improved from 6.42612 to 6.41865, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 5.9452 - root_mean_squared_error: 2.1373 - val_loss: 6.4187 - val_root_mean_squared_error: 2.2553\n",
            "Epoch 31/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.5655 - root_mean_squared_error: 2.0573\n",
            "Epoch 31: val_loss improved from 6.41865 to 6.37006, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 5.5661 - root_mean_squared_error: 2.0574 - val_loss: 6.3701 - val_root_mean_squared_error: 2.2480\n",
            "Epoch 32/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.6369 - root_mean_squared_error: 2.0782\n",
            "Epoch 32: val_loss did not improve from 6.37006\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 5.6348 - root_mean_squared_error: 2.0777 - val_loss: 6.3731 - val_root_mean_squared_error: 2.2515\n",
            "Epoch 33/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.4614 - root_mean_squared_error: 2.0381\n",
            "Epoch 33: val_loss improved from 6.37006 to 6.35132, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 5.4598 - root_mean_squared_error: 2.0377 - val_loss: 6.3513 - val_root_mean_squared_error: 2.2493\n",
            "Epoch 34/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3892 - root_mean_squared_error: 2.0240\n",
            "Epoch 34: val_loss did not improve from 6.35132\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 5.3890 - root_mean_squared_error: 2.0240 - val_loss: 6.3796 - val_root_mean_squared_error: 2.2587\n",
            "Epoch 35/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0084 - root_mean_squared_error: 1.9299\n",
            "Epoch 35: val_loss improved from 6.35132 to 6.31861, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 5.0110 - root_mean_squared_error: 1.9306 - val_loss: 6.3186 - val_root_mean_squared_error: 2.2471\n",
            "Epoch 36/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9994 - root_mean_squared_error: 1.9313\n",
            "Epoch 36: val_loss improved from 6.31861 to 6.25355, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 5.0033 - root_mean_squared_error: 1.9323 - val_loss: 6.2535 - val_root_mean_squared_error: 2.2345\n",
            "Epoch 37/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.0041 - root_mean_squared_error: 1.9346\n",
            "Epoch 37: val_loss did not improve from 6.25355\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 5.0061 - root_mean_squared_error: 1.9351 - val_loss: 6.2707 - val_root_mean_squared_error: 2.2401\n",
            "Epoch 38/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4471 - root_mean_squared_error: 2.0463\n",
            "Epoch 38: val_loss did not improve from 6.25355\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 5.4461 - root_mean_squared_error: 2.0461 - val_loss: 6.2682 - val_root_mean_squared_error: 2.2415\n",
            "Epoch 39/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.8378 - root_mean_squared_error: 1.8950\n",
            "Epoch 39: val_loss improved from 6.25355 to 6.24989, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 4.8402 - root_mean_squared_error: 1.8957 - val_loss: 6.2499 - val_root_mean_squared_error: 2.2393\n",
            "Epoch 40/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9310 - root_mean_squared_error: 1.9176\n",
            "Epoch 40: val_loss improved from 6.24989 to 6.20356, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 4.9331 - root_mean_squared_error: 1.9182 - val_loss: 6.2036 - val_root_mean_squared_error: 2.2308\n",
            "Epoch 41/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.7704 - root_mean_squared_error: 1.8820\n",
            "Epoch 41: val_loss improved from 6.20356 to 6.19374, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 4.7719 - root_mean_squared_error: 1.8824 - val_loss: 6.1937 - val_root_mean_squared_error: 2.2299\n",
            "Epoch 42/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.0234 - root_mean_squared_error: 1.9482\n",
            "Epoch 42: val_loss did not improve from 6.19374\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 5.0224 - root_mean_squared_error: 1.9480 - val_loss: 6.2004 - val_root_mean_squared_error: 2.2323\n",
            "Epoch 43/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8150 - root_mean_squared_error: 1.8961\n",
            "Epoch 43: val_loss did not improve from 6.19374\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 4.8161 - root_mean_squared_error: 1.8964 - val_loss: 6.2036 - val_root_mean_squared_error: 2.2344\n",
            "Epoch 44/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.6593 - root_mean_squared_error: 1.8548\n",
            "Epoch 44: val_loss improved from 6.19374 to 6.13107, saving model to best_gcn_model.keras\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 4.6662 - root_mean_squared_error: 1.8567 - val_loss: 6.1311 - val_root_mean_squared_error: 2.2192\n",
            "Epoch 45/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7121 - root_mean_squared_error: 1.8710\n",
            "Epoch 45: val_loss did not improve from 6.13107\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 4.7136 - root_mean_squared_error: 1.8714 - val_loss: 6.1810 - val_root_mean_squared_error: 2.2317\n",
            "Epoch 46/50\n",
            "\u001b[1m175/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4474 - root_mean_squared_error: 2.0517\n",
            "Epoch 46: val_loss did not improve from 6.13107\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 5.4375 - root_mean_squared_error: 2.0493 - val_loss: 6.2265 - val_root_mean_squared_error: 2.2426\n",
            "Epoch 47/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.6617 - root_mean_squared_error: 1.8610\n",
            "Epoch 47: val_loss did not improve from 6.13107\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 4.6623 - root_mean_squared_error: 1.8612 - val_loss: 6.1520 - val_root_mean_squared_error: 2.2275\n",
            "Epoch 48/50\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.4162 - root_mean_squared_error: 1.7946\n",
            "Epoch 48: val_loss did not improve from 6.13107\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 4.4187 - root_mean_squared_error: 1.7953 - val_loss: 6.2338 - val_root_mean_squared_error: 2.2466\n",
            "Epoch 49/50\n",
            "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.2919 - root_mean_squared_error: 1.7607\n",
            "Epoch 49: val_loss did not improve from 6.13107\n",
            "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 4.2945 - root_mean_squared_error: 1.7614 - val_loss: 6.1640 - val_root_mean_squared_error: 2.2313\n",
            "Test RMSE: 2.141704797744751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "from rdkit import RDLogger\n",
        "\n",
        "# Suppress specific deprecation warnings and RDKit warnings globally\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "def generate_fingerprint(smiles):\n",
        "    \"\"\"Generates a molecular fingerprint given a SMILES string.\"\"\"\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return np.zeros((1024,), dtype=float)\n",
        "        return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024), dtype=float)\n",
        "    except Exception as e:\n",
        "        print(f\"SMILES Parse Error: {e}\")\n",
        "        return np.zeros((1024,), dtype=float)\n",
        "\n",
        "def load_and_preprocess_data(filename):\n",
        "    \"\"\"Load and preprocess data.\"\"\"\n",
        "    summary_data = pd.read_csv(filename)\n",
        "    summary_data_filtered = summary_data.dropna(subset=['linker SMILES', 'Pore Limiting Diameter'])\n",
        "\n",
        "    linker_smiles = summary_data_filtered['linker SMILES']\n",
        "    features = np.stack(linker_smiles.apply(generate_fingerprint).values)\n",
        "    labels = summary_data_filtered['Pore Limiting Diameter'].values\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "def train_and_evaluate_model(features, labels, model):\n",
        "    \"\"\"Splits data, trains model, and evaluates it.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature scaling for KNN\n",
        "    if isinstance(model, KNeighborsRegressor):\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    return rmse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    features, labels = load_and_preprocess_data('filtered_summary_data.csv')\n",
        "\n",
        "    # K-Nearest Neighbors Regressor\n",
        "    knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "    knn_rmse = train_and_evaluate_model(features, labels, knn_model)\n",
        "    print(f'KNN RMSE: {knn_rmse}')\n",
        "\n",
        "    # Gradient Boosting Trees Regressor\n",
        "    gbtree_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "    gbtree_rmse = train_and_evaluate_model(features, labels, gbtree_model)\n",
        "    print(f'GBTree RMSE: {gbtree_rmse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UZT1EEJgWSG",
        "outputId": "de7eee2b-129f-4f9c-8085-0d9c12b784c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN RMSE: 2.2503007682787586\n",
            "GBTree RMSE: 2.1923753956354797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Filtering Description**\n",
        "\n",
        "Objective: Filter entries from the dataset 1M1L3D_summary.csv based on matching refcode values found in either the source or target columns of the edge list sparsified_graph_edges_blackhole_0.1.csv. The edge list file is formatted without headers and uses spaces as delimiters.\n",
        "\n",
        "\n",
        "\n",
        "Read both datasets; the summary data with headers, and the edge list as a headerless space-delimited file.\n",
        "Extract and combine unique refcode values from both source and target columns of the edge list.\n",
        "Filter the summary data to retain only rows whose refcode is in the list of extracted unique codes.\n",
        "Save the filtered data to a new CSV for further analysis.\n",
        "Outcome: This process ensures the summary dataset only contains records relevant to the connections defined in the edge list, facilitating targeted data analysis."
      ],
      "metadata": {
        "id": "6hxcZS5_mB2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the files\n",
        "summary_data = pd.read_csv('1M1L3D_summary.csv')\n",
        "edge_list = pd.read_csv('sparsified_graph_edges_blackhole_0.1.csv', delim_whitespace=True, header=None, names=['source', 'target', 'weight'])\n",
        "\n",
        "# Find unique refcodes in both 'source' and 'target' columns of the edge list\n",
        "unique_refcodes = pd.concat([edge_list['source'], edge_list['target']]).unique()\n",
        "\n",
        "# Filter the summary data to keep only rows where 'refcode' is in the list of unique refcodes\n",
        "filtered_summary_data = summary_data[summary_data['refcode'].isin(unique_refcodes)]\n",
        "\n",
        "# Save the filtered data to a new CSV file\n",
        "filtered_summary_data.to_csv('filtered_summary_data.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "BQNN8LR1kg78"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}