{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh/BBVbNY5bzg8zxCfVWnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJalali-AI/BlackHole/blob/main/Day6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter Methods: Using Correlation**\n",
        "To select features based on their correlation with the target variable, you can use pandas and scipy to compute correlation and select the most relevant features."
      ],
      "metadata": {
        "id": "Q15KGlFK58Ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-EHwDvf526k",
        "outputId": "8ad8410e-d876-4ed3-b752-bccf8af957e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Information values:\n",
            "     Feature  Mutual Information\n",
            "0  Feature1                   0\n",
            "1  Feature2                   0\n",
            "2  Feature3                   0\n",
            "Selected Features: []\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import pandas as pd\n",
        "\n",
        "# Example data\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': [10, 20, 30, 40, 50],\n",
        "    'Feature2': [5, 10, 15, 20, 25],\n",
        "    'Feature3': [15, 25, 35, 45, 55],\n",
        "    'Target': [1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# Calculate mutual information\n",
        "X = data.drop(columns='Target')\n",
        "y = data['Target']\n",
        "mutual_info = mutual_info_classif(X, y)\n",
        "\n",
        "# Show mutual information values\n",
        "mi_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mutual_info})\n",
        "selected_features = mi_df[mi_df['Mutual Information'] > 0]['Feature'].tolist()\n",
        "\n",
        "print(\"Mutual Information values:\\n\", mi_df)\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wrapper Method (Recursive Feature Elimination)**\n",
        "As shown earlier, Recursive Feature Elimination (RFE) can be used to find the best subset of features by evaluating model performance."
      ],
      "metadata": {
        "id": "fM2df1hu7cHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "rfe = RFE(model, n_features_to_select=2)\n",
        "rfe.fit(data.drop(columns='Target'), data['Target'])\n",
        "\n",
        "selected_features = data.drop(columns='Target').columns[rfe.support_].tolist()\n",
        "print(\"Selected Features with RFE:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQfjkGUr7WRw",
        "outputId": "532d47ed-9240-43e1-9e41-e7f3aa32046f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features with RFE: ['Feature1', 'Feature3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tree-Based Feature Importance**\n",
        "Tree-based models like Random Forests and Decision Trees can provide feature importances, which can be useful for feature selection."
      ],
      "metadata": {
        "id": "ihQrznX-7ojO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(data.drop(columns='Target'), data['Target'])\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "fi_df = pd.DataFrame({'Feature': data.drop(columns='Target').columns, 'Importance': feature_importances})\n",
        "selected_features = fi_df[fi_df['Importance'] > 0]['Feature'].tolist()\n",
        "\n",
        "print(\"Feature Importances:\\n\", fi_df)\n",
        "print(\"Selected Features:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXtVoCM7hTb",
        "outputId": "f0a4ae79-4996-4b6d-de10-4562a1f4cbfd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "     Feature  Importance\n",
            "0  Feature1    0.342643\n",
            "1  Feature2    0.340965\n",
            "2  Feature3    0.316392\n",
            "Selected Features: ['Feature1', 'Feature2', 'Feature3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Dataset**\n",
        "Consider a dataset with three features, where Feature1 and Feature2 are correlated with the target variable, and Feature3 is just random noise:"
      ],
      "metadata": {
        "id": "3HukT4CuA4mG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedded Methods for Feature Selection**\n",
        "\n",
        "Lasso Regression (L1 Regularization)\n",
        "•Description: Adds an L1 penalty to the cost function, reducing the coefficients of less important features to zero, effectively selecting features.\n",
        "•Use Case: Linear models where feature selection is required.\n",
        "Ridge Regression (L2 Regularization) with Coefficient Thresholding\n",
        "•Description: While Ridge doesn’t directly select features, setting a threshold on the coefficient magnitude can act as a form of feature selection.\n",
        "•Use Case: Linear models needing stable but minimally impactful features.\n",
        "Elastic Net (Combination of L1 and L2 Regularization)\n",
        "•Description: Combines L1 (for feature selection) and L2 (for stability) penalties, allowing for both feature selection and shrinkage.\n",
        "Use Case: Linear models, especially when features are correlated"
      ],
      "metadata": {
        "id": "xH2JTrhbATyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
        "\n",
        "# Generating a simple dataset\n",
        "np.random.seed(0)\n",
        "X = pd.DataFrame({\n",
        "    'Feature1': np.random.rand(10),\n",
        "    'Feature2': np.random.rand(10) * 2,\n",
        "    'Feature3': np.random.rand(10) * 0.5  # Random noise\n",
        "})\n",
        "y = 3 * X['Feature1'] + 2 * X['Feature2'] + np.random.rand(10)  # Target with some noise\n",
        "\n",
        "print(\"Dataset:\\n\", X)\n",
        "print(\"\\nTarget:\\n\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJN21mdGAs-Y",
        "outputId": "d51e7689-6f65-410f-b671-74cc69f3670a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:\n",
            "    Feature1  Feature2  Feature3\n",
            "0  0.548814  1.583450  0.489309\n",
            "1  0.715189  1.057790  0.399579\n",
            "2  0.602763  1.136089  0.230740\n",
            "3  0.544883  1.851193  0.390265\n",
            "4  0.423655  0.142072  0.059137\n",
            "5  0.645894  0.174259  0.319961\n",
            "6  0.437587  0.040437  0.071677\n",
            "7  0.891773  1.665240  0.472334\n",
            "8  0.963663  1.556314  0.260924\n",
            "9  0.383442  1.740024  0.207331\n",
            "\n",
            "Target:\n",
            " 0    5.077896\n",
            "1    5.035381\n",
            "2    4.536619\n",
            "3    5.905470\n",
            "4    1.573898\n",
            "5    2.903835\n",
            "6    2.005731\n",
            "7    6.622732\n",
            "8    6.947363\n",
            "9    5.312193\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Lasso Regression (L1 Regularization)**\n",
        "\n",
        "Lasso (L1) adds a penalty that can shrink some coefficients to zero, effectively performing feature selection."
      ],
      "metadata": {
        "id": "AAkR0Kn_BB2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X, y)\n",
        "\n",
        "print(\"Lasso Coefficients:\", lasso.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc0SX7FoBG7t",
        "outputId": "a7f4d6dc-317e-4493-8917-a4075d1f9e3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Coefficients: [0.68446817 2.1121344  0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Ridge Regression (L2 Regularization)**\n",
        "\n",
        "Ridge (L2) applies a penalty proportional to the square of the coefficients, shrinking them but not setting them to zero.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Expected Outcome: All coefficients are shrunk toward zero, but none are exactly zero. This regularization helps manage multicollinearity but keeps all features in the model."
      ],
      "metadata": {
        "id": "sMLHwJ48BT3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=0.1)\n",
        "ridge.fit(X, y)\n",
        "\n",
        "print(\"Ridge Coefficients:\", ridge.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emoSfdavBg19",
        "outputId": "e3adb004-c49e-4ee9-83d1-1436c033d267"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Coefficients: [2.78092591 2.06444915 0.21161511]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Elastic Net (Combination of L1 and L2 Regularization)**\n",
        "\n",
        "Elastic Net combines both L1 and L2 penalties, allowing for feature selection (L1 effect) and shrinkage (L2 effect).\n",
        "\n",
        "**# Explanation: **\n",
        "\n",
        "Expected Outcome: Some coefficients may be reduced to zero (like Lasso), while others are shrunk but kept (like Ridge). This combination is useful when you want both feature selection and stability."
      ],
      "metadata": {
        "id": "3S0XwqhjB1f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio balances L1 and L2\n",
        "elastic_net.fit(X, y)\n",
        "\n",
        "print(\"Elastic Net Coefficients:\", elastic_net.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tKsgEwCB0zE",
        "outputId": "1e1a1183-3ae9-4e82-fe14-91de0a04a2d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Coefficients: [0.93677728 1.98318448 0.        ]\n"
          ]
        }
      ]
    }
  ]
}